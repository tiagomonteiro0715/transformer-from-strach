# transformer-from-strach
Multi-head attention transformer from "Attention is all you need" paper code implementation

Code from : https://www.youtube.com/watch?v=U0s0f995w14


https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/transformer_from_scratch/transformer_from_scratch.py
